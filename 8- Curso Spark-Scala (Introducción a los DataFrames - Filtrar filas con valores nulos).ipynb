{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0c5d3f",
   "metadata": {},
   "source": [
    "Al trabajar en Spark DataFrame a menudo necesitamos filtrar filas con valores NULL en las columnas del DataFrame, puedes hacerlo comprobando las condiciones IS NULL o IS NOT NULL.\n",
    "\n",
    "En muchos casos los valores NULL en las columnas deben ser manejados antes de realizar cualquier operación en las columnas, ya que las operaciones en valores NULL resultan en valores inesperados. Por lo tanto, siempre es una buena práctica limpiar antes de procesar.\n",
    "\n",
    "Nota: Spark no soporta la columna === null, cuando se utiliza devuelve un error.\n",
    "\n",
    "Tenemos que manejar amablemente los valores nulos como el primer paso antes de procesar. Además, al escribir el DataFrame a los archivos, es una buena práctica para almacenar los archivos con valores NULL, ya sea por la caída de las filas con valores NULL en DataFrame o por la sustitución de los valores NULL con una cadena vacía.\n",
    "\n",
    "Antes de empezar, vamos a crear un DataFrame con filas que contengan valores NULL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b16d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://ALC-1NJW5D3.usersad.everis.int:4045\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1656937853664)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+\n",
      "| name|state|gender|\n",
      "+-----+-----+------+\n",
      "|James| null|     M|\n",
      "| Anna|   NY|     F|\n",
      "|Julia| null|  null|\n",
      "+-----+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data: Seq[(String, String, String)] = List((James,null,M), (Anna,NY,F), (Julia,null,null))\r\n",
       "import spark.implicits._\r\n",
       "columns: Seq[String] = List(name, state, gender)\r\n",
       "df: org.apache.spark.sql.DataFrame = [name: string, state: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/04 14:31:05 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped\r\n"
     ]
    }
   ],
   "source": [
    "val data = Seq(\n",
    "(\"James\",null,\"M\"),\n",
    "(\"Anna\",\"NY\",\"F\"),\n",
    "(\"Julia\",null,null)\n",
    ")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "val columns = Seq(\"name\",\"state\",\"gender\")\n",
    "val df = data.toDF(columns:_*)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea491b",
   "metadata": {},
   "source": [
    "Ahora, vamos a ver cómo filtrar las filas con valores nulos en DataFrame.\n",
    "\n",
    "## Filtrar filas con valores ``NULL`` en DataFrame\n",
    "En Spark, utilizando las funciones ``filter()`` o ``where()`` de DataFrame podemos filtrar filas con valores ``NULL`` comprobando ``IS NULL`` o ``isNULL``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814dbfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|James|null |M     |\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n",
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|James|null |M     |\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n",
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|James|null |M     |\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"state is NULL\").show(false)\n",
    "df.filter(df(\"state\").isNull).show(false)\n",
    "df.filter(col(\"state\").isNull).show(false) //Required col function import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc1a6f",
   "metadata": {},
   "source": [
    "Esto elimina todas las filas con valores nulos en la columna de estado y devuelve el nuevo DataFrame. Todos los ejemplos anteriores devuelven el mismo resultado.\n",
    "\n",
    "También se puede escribir lo mismo utilizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b470327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|name|state|gender|\n",
      "+----+-----+------+\n",
      "|Anna|NY   |F     |\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(Seq(\"state\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68265add",
   "metadata": {},
   "source": [
    "## Filtrar filas con NULL en múltiples columnas\n",
    "Veamos cómo filtrar filas con valores NULL en múltiples columnas en DataFrame. Para ello puede utilizar los operadores AND o &&."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea43a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n",
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n",
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"state is NULL AND gender is NULL\").show(false)\n",
    "df.filter(df(\"state\").isNull && df(\"gender\").isNull).show(false)\n",
    "df.filter(col(\"state\").isNull && col(\"gender\").isNull).show(false) //Required col function import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4193a",
   "metadata": {},
   "source": [
    "## Filtrar filas con ``IS NOT NULL`` o ``isNotNull``\n",
    "``IS NOT NULL`` o ``isNotNull`` se utiliza para filtrar las filas que son ``NOT NULL`` en las columnas de Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e0240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|name|state|gender|\n",
      "+----+-----+------+\n",
      "|Anna|NY   |F     |\n",
      "+----+-----+------+\n",
      "\n",
      "+----+-----+------+\n",
      "|name|state|gender|\n",
      "+----+-----+------+\n",
      "|Anna|NY   |F     |\n",
      "+----+-----+------+\n",
      "\n",
      "+----+-----+------+\n",
      "|name|state|gender|\n",
      "+----+-----+------+\n",
      "|Anna|NY   |F     |\n",
      "+----+-----+------+\n",
      "\n",
      "+----+-----+------+\n",
      "|name|state|gender|\n",
      "+----+-----+------+\n",
      "|Anna|NY   |F     |\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"state is not NULL\").show(false)\n",
    "df.filter(\"NOT state is NULL\").show(false)\n",
    "df.filter(df(\"state\").isNotNull).show(false)\n",
    "df.filter(col(\"state\").isNotNull).show(false) //Required col function import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04afe46b",
   "metadata": {},
   "source": [
    "## Spark SQL Filtra filas con valores ``NULL``\n",
    "Si estás familiarizado con Spark SQL, puedes comprobar ``IS NULL`` y ``IS NOT NULL`` para filtrar las filas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6ef4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|James|null |M     |\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n",
      "+-----+-----+------+\n",
      "|name |state|gender|\n",
      "+-----+-----+------+\n",
      "|Julia|null |null  |\n",
      "+-----+-----+------+\n",
      "\n",
      "+----+-----+------+\n",
      "|name|state|gender|\n",
      "+----+-----+------+\n",
      "|Anna|NY   |F     |\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"DATA\")\n",
    "spark.sql(\"SELECT * FROM DATA where STATE IS NULL\").show(false)\n",
    "spark.sql(\"SELECT * FROM DATA where STATE IS NULL AND GENDER IS NULL\").show(false)\n",
    "spark.sql(\"SELECT * FROM DATA where STATE IS NOT NULL\").show(false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
